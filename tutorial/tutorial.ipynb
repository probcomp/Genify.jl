{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# An Introduction to Genify\n\nGenify is a tool that allows users to transform stochastic code written in\nplain Julia into generative functions contolled by the [Gen probabilistic\nprogramming system](https://www.gen.dev). This tutorial show how Genify\nworks, and how you can use it to enable programmable inference over\nstochastic Julia code."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Pkg\nPkg.activate(\".\")\nPkg.instantiate()"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Genify?\n\nThere are two broad use cases for Genify:\n1. Programmable inference over existing stochastic Julia code (e.g. simulators)\n2. PPL-compatibility for plain Julia code, without depending upon Gen\nWe'll motivate each of these use cases in turn.\n\n### Programmable inference over existing stochastic code\n\nA wide variety of libraries written in Julia implement stochastic simulators of\nnatural and social phenomena for the purposes of computational science. For\nexample, the following function implements a stochastic, discrete time,\nSusceptible-Infected-Recovered (SIR) model of epidemic spread:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Random, Distributions\n\nfunction sir_model(T::Int, init_pop::Vector{Int},\n                   β::Float64=0.5, γ::Float64=0.02)\n    # Initialize population history\n    pop_history = zeros(Int, 3, T)\n    pop_history[:, 1] = init_pop\n    tot_pop = sum(init_pop)\n    for t in 2:T\n        susceptible, infected, recovered = pop_history[:, t-1]\n        # Sample number of individuals who are newly infected and recovered\n        newly_infected = rand(Binomial(susceptible, β * infected / tot_pop))\n        newly_recovered = rand(Binomial(infected, γ))\n        # Update the population counts\n        susceptible -= newly_infected\n        infected += newly_infected - newly_recovered\n        recovered += newly_recovered\n        pop_history[:, t] = [susceptible, infected, recovered]\n    end\n    return pop_history\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This allows us to perform forward simulation of how a viral epidemic\nmight evolve over time:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots\npop_history = sir_model(100, [990, 10, 0], 0.5, 0.1)\nplot_sir! = (x, plt, alpha=1.0, color=palette(:default)[1:3]') ->\n    plot!(plt, x', ylabel=\"Population\", xlabel=\"Time\", lw=2, margin=10*Plots.px,\n          labels=[\"Susceptible\" \"Infected\" \"Recovered\"], alpha=alpha,\n          fg_color_legend=nothing, bg_color_legend=nothing, color=color)\nplot_sir = x -> plot_sir!(x, plot(size=(800, 300), dpi=192))\nplot_sir(pop_history)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, because `sir_model` isn't written using a probabilistic\nprogramming system like Gen, we can't perform more complex queries, such as:\n- Given that 100 people were infected on day 10, how is the rest of the\n  epidemic likely to evolve?\n- If at most 15 people recovered every day starting from day 20, what is the\n  likely recovery rate parameter, γ?\n\nIn order to answer these and other queries, we need the following capabilities\nprovided by a probabilistic programming system like Gen:\n- Constraining of observed random variables\n- Sampling random variables from custom proposal distributions\n- Computing likelihoods and importance ratios for execution traces\n- Seletively updating random choices and subroutines (for MCMC inference)\n\nHere's where Genify comes to the rescue! Using the `genify` function, we can\ntransform `sir_model` into an equivalent generative function in Gen:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Gen, Genify\n# Transform the `sir_model` method by providing its type signature\ngen_sir_model = genify(sir_model, Int, Vector{Int}, Float64, Float64);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can sample from this model while constraining specific random variables:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Sample a trace from the model where 50 people were infected on day 10\ntrace, weight = generate(gen_sir_model, (100, [990, 10, 0], 0.5, 0.1),\n                         choicemap((:newly_infected => 10 - 1, 100)))\n# Check that trace has the right value\n@assert trace[:newly_infected => 10 - 1] == 100\n# Plot sampled trace\nplot_sir(get_retval(trace))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because `gen_sir_model` supports Gen's generative function interface,\nGenify allows users to perform Bayesian inference over the model using Gen's\ninference library, including generic algorithms such as `importance_sampling`,\nbut also custom algorithms that compose Gen's inference primitives.\n\n### PPL-compatibility for plain Julia code\n\nAnother use case for Genify is so that developers can write stochastic Julia\ncode that is *Gen-compatible*, but that still works without requiring Gen as a\ndependency.\n\nThis might arise when implementing a randomized algorithm to solve some task\n(e.g. sample-based motion planning). Most of the time, one simply uses the\nalgorithm to solve the task. This doesn't require a probabilistic programming\nsystem. But sometimes, one might want to *perform inference* over the randomized\nalgorithm, asking questions like: what choices must the randomized algorithm\nhave sampled in order to produce the output it did? This sort of question\narises in domains like Bayesian inverse planning, where the task is to infer\nthe goals of rational agents from observations of their behavior.\n\nFrom a software engineering point of view then, it would be ideal if we could\nwrite the randomized algorithm without depending upon Gen, reducing library\nbloat, but still use it with Gen when desired. Genify enables exactly this use\ncase, because it can transform any Julia function into a Gen function.\n\nAs a toy example, we can write a *manually addressed* Julia function that\nimplements an ϵ-greedy policy for a\n[multi-armed bandit](https://en.wikipedia.org/wiki/Multi-armed_bandit):"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using TracedRandom # Provides support for rand(:addr, distribution) syntax\n\nfunction bandit_policy(max_pulls::Int, levers::Vector{Float64}, ϵ::Float64)\n    accum_rewards = zeros(Float64, length(levers))\n    n_pulls = zeros(Int, length(levers))\n    for k in 1:max_pulls\n        if rand(:explore => k, Bernoulli(ϵ))\n            idx = rand(:explore_idx => k, DiscreteUniform(1, length(levers)))\n        else\n            mean_rewards = [n > 0 ? r / n : 0.0\n                            for (r, n) in zip(accum_rewards, n_pulls)]\n            idx = argmax(mean_rewards)\n        end\n        reward = rand(:reward => k, Normal(levers[idx], 1.0))\n        accum_rewards[idx] += reward\n        n_pulls[idx] += 1\n    end\n    return (accum_rewards, n_pulls)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then transform this using Genify's manual addressing mode. Sampling\na trace from this model shows the expected structure"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "gen_policy = genify(:manual, bandit_policy, Int, Vector{Float64}, Float64)\ntrace, weight = generate(gen_policy, (5, [2.0, 5.0, 10.0], 0.1),\n                         choicemap((:explore => 3, true)))\nget_choices(trace)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How does it work?\n\nHaving motivated the usefulness of Genify, we now give a brief introduction to\nits implementation.\n\nSome probabilistic programming systems, such as Pyro, make use of the fact\ntheir host languages (e.g., Python) are interpreted languages. This enables an\nimplementation strategy called *non-standard interpretation*: a custom\ninterpreter executes code in the host language, imbuing that code with new\nsemantics when inference operations like conditioning are performed.\n\nHowever, unlike Python, Julia is a *compiled* language, which makes it seem\ndifficult to implement a similar strategy. After all, if pre-written Julia\ncode is already compiled, how can one transform that compiled code into Gen?\n\n### Compiler injection\n\nThankfully, we can overcome this challenge because Julia's just-in-time (JIT)\ncompilation strategy and support for meta-programming provide the following\ntwo features:\n1. Every Julia method is first lowered to a single-site assignment (SSA)\n   intermediate representation (IR) before compilation to machine code.\n   This IR information is stored away, and is accessible for any (non-primitive)\n   Julia method.\n2. Julia supports meta-programming via *generated functions*: functions with\n   dynamically generated method bodies, based on the types of the provided\n   arguments. This allows specialized code to be automatically generated\n   and compiled when a function is called with particular types.\n\nThese two features enable an implementation strategy similar to non-standard\ninterpretation: *compiler injection*, also called\n[*overdubbing*](https://julia.mit.edu/Cassette.jl/stable/). The basic process\nis as follows:\n1. Write a generated function `transform` which takes another function `fn`\n   as input, along with its arguments `args`.\n2. Lookup the IR of `fn` within `transform`, and modify the IR with new behavior\n3. Pass the modified IR back to the Julia compiler, to get a compiled method\n   `transformed_fn`, and run that method on `args`.\n\nBy modifying the IR, we can imbue the original function with new semantics:\ne.g., computing likelihood weights, in addition ta sampling. Unlike non-standard\ninterpretation, this transformation procedure is performed only once,\nduring the first call to `transform(fn, args...)`. Subsequent calls to\n`transform(fn, args...)` will simply execute the already compiled method body,\nmodifications in-hand.\n\n### A simple example\n\nTo illustrate what this process looks like, let's see it applied to a simple\nexample. The following two functions define a model of noisy weighing scale,\nweighing an object of unknown mass:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function model(n::Int)\n    mass = rand(Normal(5, 1))\n    obs = observe(mass, n)\nend\n\nfunction observe(mass::Real, n::Int)\n    obs = Float64[]\n    for i in 1:n\n        m = rand(Normal(mass, 2))\n        push!(obs, m)\n    end\n    return obs\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `IRTools.jl` package, we can inspect the IR of `model` and `observe`:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using IRTools: IR, isexpr\nprintln(\"== model IR ==\")\nIR(typeof(model), Int) |> display\nprintln(\"== observe IR ==\")\nIR(typeof(observe), Real, Int) |> display"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the IR of `model` is straightforward. The IR of `observe`\nis more complicated: it has multiple basic blocks because it contains a\n`for` loop.\n\nLet's say we want to modify the behavior of `model` by replacing every\ncall to `rand` with some constant value. We can do this by just looping over\nthe IR and modifying matching statements:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function derandomize_ir!(ir::IR)\n    for (x, stmt) in ir\n        if !isexpr(stmt.expr, :call) continue end\n        fn, args = stmt.expr.args\n        if !(fn isa GlobalRef && fn.name == :rand) continue end\n        ir[x] = 0.0\n    end\n    return ir\nend\nIR(typeof(model), Int) |> derandomize_ir! |> display"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the call to `rand` has been replaced by `0.0`.\n\nUsing `IRTools.jl`, we can perform this IR transformation within a generated\nfunction called a *dynamo* (a \"dynamic macro\"):"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using IRTools: @dynamo\n@dynamo function derandomize(args...)\n    ir = IR(args...)\n    return derandomize_ir!(ir)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now call this dynamo on the function we want to derandomize:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "println(\"Derandomized `observe`:\")\nderandomize(observe, 10.0, 5) |> display\nprintln(\"Derandomized `model`:\")\nderandomize(model, 5) |> display"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that when `observe` is derandomized, every call to `rand` is replaced\nby a zero, so it ends up returning a vector of five zeroes. However, the\nderandomized version of model still returns what looks like a list of random\nnumbers. This is because `derandomize_ir!` does not recurse into nested\nfunctions. As result, it replaces only the call to `rand` within `model`\nitself, but not within its nested call to `observe`.\n\nTo fix this, we need to modify the `derandomize` dynamo to recursively wrap\nitself around nested functions:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@dynamo function derandomize(args...)\n    ir = IR(args...)\n    if ir == nothing return end\n    for (x, stmt) in ir\n        if !isexpr(stmt.expr, :call) continue end\n        fn, args = stmt.expr.args[1], stmt.expr.args[2:end]\n        if fn isa GlobalRef && fn.name == :rand\n            ir[x] = 0.0\n        else\n            ir[x] = Expr(:call, derandomize, fn, args...)\n        end\n    end\n    return ir\nend\n\nprintln(\"Derandomized `model`:\")\nderandomize(model, 5) |> display"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The derandomized version of `model` now returns a vector of five zeroes,\nas desired.\n\nThis basic implementation strategy allows us to transform Julia methods with\nrandom primitives like `rand`, `randn` or `randperm` into `DynamicDSLFunction`s\nin Gen. Calls to primitives are replaced by calls to Gen distributions, wrapped\nwithin the `Gen.traceat` method.\n[Dispatch on function types](https://fluxml.ai/IRTools.jl/latest/dynamo/#Using-Dispatch-1)\nsimplifies the implementation considerably, and additional tricks are used to\nwrap nested function calls within `DynamicDSLFunction`s. Interested readers\nare encouraged to browse the source code.\n\n## Programmable inference with Genify\n\nNow that we've seen how Genify works, let's use it do some inference!\nRecall the first query we wanted to ask about our SIR epidemic model:\n- Given that 100 people were infected on day 10, how is the rest of the\n  epidemic likely to evolve?\n\nTo answer this, we can just apply importance sampling while constraining the\nnumber of newly infected to be 100 on day 10. For comparison, we also sample\nsimulations where only 30 people are newly infected on that day."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "n_samples = 50\ntraces_100, weights_100, _ =\n    importance_sampling(gen_sir_model, (100, [990, 10, 0], 0.5, 0.1),\n                        choicemap((:newly_infected => 10 - 1, 100)), n_samples)\ntraces_30, weights_30, _ =\n    importance_sampling(gen_sir_model, (100, [990, 10, 0], 0.5, 0.1),\n                        choicemap((:newly_infected => 10 - 1, 30)), n_samples);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then visualize the sampled traces, emphasizing those traces with\nlarger importance weights:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot_sir_traces = (traces, weights) -> begin\n    plt = plot(size=(600, 200), dpi=192)\n    for (tr, w) in zip(traces, weights)\n        plot_sir!(get_retval(tr), plt, exp(w))\n    end\n    plot!(plt, legend=false)\nend\nplt_100 = plot_sir_traces(traces_100, weights_100)\ntitle!(\"(a) 100 people infected on day 10\")\nplt_30 = plot_sir_traces(traces_30, weights_30)\ntitle!(\"(b) 30 people infected on day 10\")\nplot(plt_100, plt_30, layout=(2, 1), size=(800, 600), dpi=192)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that in simulations where 100 people are infected on day 10,\nthe peak in infected individuals arrives considerably earlier than when\n30 people are infected on the same day.\n\nNow let's try tackling the second query:\n- If at most 15 people recovered every day starting from day 20, what is\n  the likely recovery rate parameter, γ?\n\nThis query is more complex than the first, for the following reasons:\n- It requires us to extend the model with uncertainty over the parameters\n  β and γ, in order to perform *Bayesian parameter estimation*.\n- We need some way to sample simulations where at most 15 infected individuals\n  recover everyday, from day 20 onward.\n\nFortunately, both of these are easy to do with Gen! To extend `sir_model` with\nparameter uncertainty, we can simply wrap it in an `@gen` function which\nintroduces priors over β and γ:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@gen function param_sir_model(T::Int, init_pop::Vector{Int})\n    β ~ uniform(0.0, 1.0)\n    γ ~ uniform(0.0, 1.0)\n    {*} ~ gen_sir_model(T, init_pop, β, γ)\nend;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how, in the final line, we sampled from `gen_sir_model`, the transformed\nversion of `sir_model`, since `gen_sir_model` is like any generative function\nin Gen.\n\nIn order to sample simulations where at most 15 infected individuals recover\nfrom day 20 onwards, the simplest thing we could do is rejection sampling:\nRun `param_sir_model` many times, and throw away all samples which do not meet\nthe above condition. Evidently, this is wasteful, and can lead to high variance\nwhen the condition is rare. Instead, we can use a *proposal distribution*,\nspecified as a generative function, that only samples simulations that meet\nthe condition. Furthermore, since we have Genify at our disposal, we can write\nthis proposal using plain Julia:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function sir_proposal(T::Int, init_pop::Vector{Int}, day::Int, thresh::Int)\n    # Sample latent parameters\n    β = rand(Uniform(0.0, 1.0))\n    γ = rand(Uniform(0.0, 1.0))\n    # Initialize population history\n    pop_history = zeros(Int, 3, T)\n    pop_history[:, 1] = init_pop\n    tot_pop = sum(init_pop)\n    for t in 2:T\n        susceptible, infected, recovered = pop_history[:, t-1]\n        # Sample newly infected individuals\n        newly_infected = rand(Binomial(susceptible, β * infected / tot_pop))\n        # Sample newly recovered individuals from a truncated distribution\n        r_dist = t >= day ?\n            truncated(Binomial(infected, γ), -1, thresh) : Binomial(infected, γ)\n        newly_recovered = rand(r_dist)\n        # Update the population counts\n        susceptible -= newly_infected\n        infected += newly_infected - newly_recovered\n        recovered += newly_recovered\n        pop_history[:, t] = [susceptible, infected, recovered]\n    end\n    return pop_history\nend\ngen_sir_proposal = genify(sir_proposal, Int, Vector{Int}, Int, Int);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that `sir_proposal` is almost identical to `sir_model`, except we have\nmade sure to (i) sample the latent parameters β and γ; (ii) sample newly\nrecovered individuals from a Binomial distribution truncated at the threshold\nof 15. Change (i) is necessary to ensure that `sir_proposal` matches the\ntrace structure of `param_sir_model`, while change (ii) ensures that our\ncondition is always met.\n\nUsing this proposal distribution, we can now perform importance sampling\nin order to estimate the posterior distribution over γ:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "model_args = (100, [990, 10, 0])\nrecov_day, recov_thresh = 20, 15\nprop_args = (model_args..., recov_day, recov_thresh)\nn_samples = 5000\ntraces, weights, _ =\n    importance_sampling(param_sir_model, model_args, choicemap(),\n                        gen_sir_proposal, prop_args, n_samples)\n\nγ_mean = sum(getindex.(traces, :γ) .* exp.(weights))\nprintln(\"γ posterior mean estimate: $γ_mean\")\nhistogram(getindex.(traces, :γ), bins=20, weights=exp.(weights);\n          linecolor=palette(:default)[1], legend=false,\n          xlabel=\"γ (recovery rate)\", ylabel=\"Probability\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importance sampling produces a rather unintuitive posterior over the\nrecovery rate γ. Most of the posterior mass is towards the right, suggesting\na high recovery rate, with only a small peak for very low values of γ. This is\ndespite the condition stipulating that not many people recover everyday after\nday 20. The intuitive explanation for this is a low recovery rate, which is\ncaptured by the small peak to the left. However, there is another explanation:\nthe population recovers so quickly that by day 20, there are no more\ninfected individuals, and so the number of new recoveries each day is zero from\nthen on! Without a Bayesian analysis, we may not have discovered this competing\ndiversity of explanations.\n\nThat brings us to the end of this tutorial! For more examples of Genify being\nused for programmable inference, check out the `examples` directory in the\n[Genify.jl](https://github.com/probcomp/Genify.jl) repository. To learn more\nabout Gen and programmable inference, check out the website at\n<https://www.gen.dev/>."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.3.1"
    },
    "kernelspec": {
      "name": "julia-1.3",
      "display_name": "Julia 1.3.1",
      "language": "julia"
    }
  },
  "nbformat": 4
}
